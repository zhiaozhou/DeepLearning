{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:51:21.335139Z",
     "start_time": "2018-02-27T01:51:17.389855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "import imageio\n",
    "import scipy.misc\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:51:21.555387Z",
     "start_time": "2018-02-27T01:51:21.548368Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_files_train(folder):\n",
    "    \"\"\"\n",
    "    Given path to folder, returns list of files in it\n",
    "    \"\"\"\n",
    "    filenames = [file for file in glob.glob(folder+'*/*')]\n",
    "    filenames.sort(key= lambda x:int(x[11:x.index('_')]))\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:51:22.072688Z",
     "start_time": "2018-02-27T01:51:22.066672Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_files_test(folder):\n",
    "    \"\"\"\n",
    "    Given path to folder, returns list of files in it\n",
    "    \"\"\"\n",
    "    filenames = [file for file in glob.glob(folder+'*/*')]\n",
    "    filenames.sort(key= lambda x:int(x[10:x.index('.')]))\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:54:58.673451Z",
     "start_time": "2018-02-27T01:54:58.472497Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions, DO NOT modify this\n",
    "\n",
    "def get_img_array(path):\n",
    "    \"\"\"\n",
    "    Given path of image, returns it's numpy array\n",
    "    \"\"\"\n",
    "    return imageio.imread(path)\n",
    "\n",
    "def resize_img(img_arr, target_dim=(50, 50)):\n",
    "    \"\"\"\n",
    "    Resizes img represented as numpy array\n",
    "    \"\"\"\n",
    "    return scipy.misc.imresize(img_arr, target_dim)\n",
    "\n",
    "def get_label(filepath, label2id):\n",
    "    \"\"\"\n",
    "    Files are assumed to be labeled as: /path/to/file/999_frog.png\n",
    "    Returns label for a filepath\n",
    "    \"\"\"\n",
    "    tokens = filepath.split('/')\n",
    "    label = tokens[-1].split('_')[1][:-4]\n",
    "    if label in label2id:\n",
    "        return label2id[label]\n",
    "    else:\n",
    "        sys.exit(\"Invalid label: \" + label)\n",
    "\n",
    "# Functions to load data\n",
    "\n",
    "def get_labels(folder, label2id):\n",
    "    \"\"\"\n",
    "    Returns vector of labels extracted from filenames of all files in folder\n",
    "    :param folder: path to data folder\n",
    "    :param label2id: mapping of text labels to numeric ids. (Eg: automobile -> 0)\n",
    "    \"\"\"\n",
    "    files = get_files_train(folder)\n",
    "    y = []\n",
    "    for f in files:\n",
    "        y.append(get_label(f,label2id))\n",
    "    return np.array(y)\n",
    "\n",
    "def one_hot(y, num_classes=10):\n",
    "    \"\"\"\n",
    "    Converts each label index in y to vector with one_hot encoding\n",
    "    \"\"\"\n",
    "    y_one_hot = np.zeros((y.shape[0], num_classes))\n",
    "    y_one_hot[y] = 1\n",
    "    return y_one_hot.T\n",
    "\n",
    "def get_label_mapping(label_file):\n",
    "    \"\"\"\n",
    "    Returns mappings of label to index and index to label\n",
    "    The input file has list of labels, each on a separate line.\n",
    "    \"\"\"\n",
    "    with open(label_file, 'r') as f:\n",
    "        id2label = f.readlines()\n",
    "        id2label = [l.strip() for l in id2label]\n",
    "    label2id = {}\n",
    "    count = 0\n",
    "    for label in id2label:\n",
    "        label2id[label] = count\n",
    "        count += 1\n",
    "    return id2label, label2id\n",
    "\n",
    "def get_images(folder):\n",
    "    \"\"\"\n",
    "    returns numpy array of all samples in folder\n",
    "    each column is a sample resized to 30x30 and flattened\n",
    "    \"\"\"\n",
    "    if 'train' in folder:\n",
    "        files = get_files_train(folder)\n",
    "    elif 'test' in folder:\n",
    "        files = get_files_test(folder)\n",
    "    images = []\n",
    "    count = 0\n",
    "\n",
    "    for f in files:\n",
    "        count += 1\n",
    "        if count % 5000 == 0:\n",
    "            print(\"Loaded {}/{}\".format(count,len(files)))\n",
    "#         if count > 100:\n",
    "#             break\n",
    "        img_arr = get_img_array(f)/255.0\n",
    "        images.append(img_arr)\n",
    "#     X = tf.map_fn(lambda image: tf.image.per_image_standardization(image), images, tf.int32)\n",
    "    X = np.array(images)\n",
    "#     X = images\n",
    "    return X\n",
    "\n",
    "def get_train_data(data_root_path, suffix=\"train\"):\n",
    "    \"\"\"\n",
    "    Return X and y\n",
    "    \"\"\"\n",
    "    train_data_path = data_root_path + suffix\n",
    "    id2label, label2id = get_label_mapping(data_root_path+'labels.txt')\n",
    "    print(label2id)\n",
    "    X = get_images(train_data_path)\n",
    "    y = get_labels(train_data_path, label2id)\n",
    "    return X, y\n",
    "\n",
    "def save_predictions(filename, y):\n",
    "    np.save(filename, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:55:40.696400Z",
     "start_time": "2018-02-27T01:54:59.524632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n",
      "Loaded 5000/45000\n",
      "Loaded 10000/45000\n",
      "Loaded 15000/45000\n",
      "Loaded 20000/45000\n",
      "Loaded 25000/45000\n",
      "Loaded 30000/45000\n",
      "Loaded 35000/45000\n",
      "Loaded 40000/45000\n",
      "Loaded 45000/45000\n",
      "Train data loading done\n"
     ]
    }
   ],
   "source": [
    "# Load train data\n",
    "data_root_path = 'data/'\n",
    "# data_root_path = './cifar10-simple/'\n",
    "X_train, y_train = get_train_data(data_root_path) # this may take a few minutes\n",
    "# X_centered = (X_train - np.mean(X_train, axis=1)[:, np.newaxis])\n",
    "# X_div = (X_centered / np.std(X_centered, axis=1)[:, np.newaxis])\n",
    "# X_train = X_div\n",
    "print('Train data loading done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:55:47.517563Z",
     "start_time": "2018-02-27T01:55:47.487457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 32, 32, 3) (45000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:56:56.386450Z",
     "start_time": "2018-02-27T01:56:51.174111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5000/5000\n",
      "Test data loading done\n"
     ]
    }
   ],
   "source": [
    "#Load test data\n",
    "X_test = get_images(data_root_path + 'test')\n",
    "# X_centered = (X_test - np.mean(X_test, axis=1)[:, np.newaxis])\n",
    "# X_div = (X_centered / np.std(X_centered, axis=1)[:, np.newaxis])\n",
    "# X_test = X_div\n",
    "print('Test data loading done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:57:02.915489Z",
     "start_time": "2018-02-27T01:57:02.910475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 32, 32, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:57:06.604252Z",
     "start_time": "2018-02-27T01:57:06.554538Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_matrix(labels, C):\n",
    "    \"\"\"\n",
    "    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n",
    "                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) \n",
    "                     will be 1. \n",
    "                     \n",
    "    Arguments:\n",
    "    labels -- vector containing the labels \n",
    "    C -- number of classes, the depth of the one hot dimension\n",
    "    \n",
    "    Returns: \n",
    "    one_hot -- one hot matrix\n",
    "    \"\"\"\n",
    "    # Create a tf.constant equal to C (depth), name it 'C'. (approx. 1 line)\n",
    "    C = tf.constant(C, name='C')\n",
    "    \n",
    "    # Use tf.one_hot, be careful with the axis (approx. 1 line)\n",
    "    one_hot_matrix = tf.one_hot(labels,C,1)\n",
    "    \n",
    "    # Create the session (approx. 1 line)\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # Run the session (approx. 1 line)\n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "    \n",
    "    # Close the session (approx. 1 line). See method 1 above.\n",
    "    sess.close()\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:57:10.656825Z",
     "start_time": "2018-02-27T01:57:07.722003Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = one_hot_matrix(y_train,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:57:14.336584Z",
     "start_time": "2018-02-27T01:57:14.327110Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_H0 -- scalar, height of an input image\n",
    "    n_W0 -- scalar, width of an input image\n",
    "    n_C0 -- scalar, number of channels of the input\n",
    "    n_y -- scalar, number of classes\n",
    "        \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [None, n_y] and dtype \"float\"\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (â‰ˆ2 lines)\n",
    "    X = tf.placeholder(tf.float32,shape=[None,n_H0,n_W0,n_C0],name='X')\n",
    "    Y = tf.placeholder(tf.float32,shape=[None,n_y],name='Y')\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:57:15.386521Z",
     "start_time": "2018-02-27T01:57:15.371512Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes weight parameters to build a neural network with tensorflow. \n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, W2\n",
    "    \"\"\"\n",
    "    \n",
    "        \n",
    "    ### START CODE HERE ### (approx. 2 lines of code)\n",
    "    W1 = tf.get_variable('W1',[5,5,3,64],initializer= tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    b1 = tf.get_variable('b1',[64],initializer= tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W2 = tf.get_variable('W2',[5,5,64,64],initializer= tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    b2 = tf.get_variable('b2',[64],initializer= tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2,\n",
    "                 'b1':b1,\n",
    "                 'b2':b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:57:16.391967Z",
     "start_time": "2018-02-27T01:57:16.383945Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    return tf.nn.lrn(x, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "def max_pool_2x2(x): return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T04:17:18.433108Z",
     "start_time": "2018-02-27T04:17:18.390485Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation_cost(X,Y,parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"W2\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    b1 = parameters['b1']\n",
    "    b2 = parameters['b2']\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # CONV2D: stride of 1, padding 'SAME'\n",
    "    Z1 = conv2d(X,W1)+b1\n",
    "    # RELU\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    # MAXPOOL: window 8x8, sride 8, padding 'SAME'\n",
    "    P1 = norm(max_pool_2x2(A1))\n",
    "    # CONV2D: filters W2, stride 1, padding 'SAME'\n",
    "    Z2 = conv2d(P1,W2)+b2\n",
    "    # RELU\n",
    "    A2 = norm(tf.nn.relu(Z2))\n",
    "    # MAXPOOL: window 4x4, stride 4, padding 'SAME'\n",
    "    P2 = max_pool_2x2(A2)\n",
    "    # FLATTEN\n",
    "    P2 = tf.contrib.layers.flatten(P2)\n",
    "    \n",
    "    # 10 neurons in output layer. Hint: one of the arguments should be \"activation_fn=None\" \n",
    "    \n",
    "    keep_prob = tf.placeholder(tf.float32,name='keep_prob')\n",
    "    P2 = tf.nn.dropout(P2,keep_prob)\n",
    "    Z3 = tf.contrib.layers.fully_connected(P2,10,activation_fn=None)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z3,labels=Y))\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return Z3, keep_prob, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T04:17:18.637698Z",
     "start_time": "2018-02-27T04:17:18.591570Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n",
    "    mini_batch_size -- size of the mini-batches, integer\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(seed)            # To make your \"random\" minibatches the same as ours\n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "        \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:,:]\n",
    "    shuffled_Y = Y[permutation,:]\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = shuffled_X[k*mini_batch_size:(k+1)*mini_batch_size,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[k*mini_batch_size:(k+1)*mini_batch_size,:]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches*mini_batch_size:,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches*mini_batch_size:,:]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T04:17:19.075419Z",
     "start_time": "2018-02-27T04:17:18.844212Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test,test, learning_rate = 0.1,\n",
    "          num_epochs = 100, minibatch_size = 64, print_cost = True, optimizer='GD',kp=1.0):\n",
    "    \"\"\"\n",
    "    Implements a three-layer ConvNet in Tensorflow:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set\n",
    "    Y_train -- test set\n",
    "    X_test -- training set\n",
    "    Y_test -- test set\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    train_accuracy -- real number, accuracy on the train set (X_train)\n",
    "    test_accuracy -- real number, testing accuracy on the test set (X_test)\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    print(test.shape)\n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep results consistent (tensorflow seed)\n",
    "    seed = 3                                          # to keep results consistent (numpy seed)\n",
    "    (m, n_H0, n_W0, n_C0) = X_train.shape             \n",
    "    n_y = Y_train.shape[1]                            \n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of the correct shape\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = create_placeholders(n_H0,n_W0,n_C0,n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z3,keep_prob,cost = forward_propagation_cost(X,Y,parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    #global_ = tf.Variable(tf.constant(0))  \n",
    "    global_step = tf.Variable(0)\n",
    "    lr = tf.train.exponential_decay(learning_rate,global_step,705,0.88,staircase=False)\n",
    "    if optimizer == 'GD':\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr).minimize(cost,global_step=global_step)\n",
    "    elif optimizer == 'adam':\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost,global_step=global_step)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables globally\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            minibatch_cost = 0.\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "            \n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                # IMPORTANT: The line that runs the graph on a mfinibatch.\n",
    "                # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , temp_cost = sess.run([optimizer,cost],feed_dict={keep_prob:kp,X:minibatch_X,Y:minibatch_Y})\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "                \n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(minibatch_cost)\n",
    "        \n",
    "        \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "        predict_op = tf.argmax(Z3, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        save_predictions('ans-zz1749.npy',predict_op.eval({X: test,keep_prob:1.0}))\n",
    "        # Calculate the correct predictions\n",
    "        #train_accuracy = accuracy.eval({X: X_train, Y: Y_train,keep_prob:1.0})\n",
    "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test,keep_prob:1.0})\n",
    "        #print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T03:12:40.915886Z",
     "start_time": "2018-02-27T03:12:40.305117Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_t,X_d,Y_t,Y_d = train_test_split(X_train,Y_train,test_size = 1./3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T04:30:40.943795Z",
     "start_time": "2018-02-27T04:17:27.051219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 32, 32, 3)\n",
      "Cost after epoch 0: 1.576328\n",
      "Cost after epoch 1: 1.232955\n",
      "Cost after epoch 2: 1.084014\n",
      "Cost after epoch 3: 0.985320\n",
      "Cost after epoch 4: 0.920782\n",
      "Cost after epoch 5: 0.874631\n",
      "Cost after epoch 6: 0.832032\n",
      "Cost after epoch 7: 0.803521\n",
      "Cost after epoch 8: 0.777315\n",
      "Cost after epoch 9: 0.751912\n",
      "Cost after epoch 10: 0.734312\n",
      "Cost after epoch 11: 0.715096\n",
      "Cost after epoch 12: 0.703006\n",
      "Cost after epoch 13: 0.687472\n",
      "Cost after epoch 14: 0.677818\n",
      "Cost after epoch 15: 0.669790\n",
      "Cost after epoch 16: 0.661827\n",
      "Cost after epoch 17: 0.655696\n",
      "Cost after epoch 18: 0.648646\n",
      "Cost after epoch 19: 0.643950\n",
      "Cost after epoch 20: 0.637064\n",
      "Cost after epoch 21: 0.631884\n",
      "Cost after epoch 22: 0.627788\n",
      "Cost after epoch 23: 0.629842\n",
      "Cost after epoch 24: 0.622781\n",
      "Cost after epoch 25: 0.622186\n",
      "Cost after epoch 26: 0.622082\n",
      "Cost after epoch 27: 0.619738\n",
      "Cost after epoch 28: 0.613510\n",
      "Cost after epoch 29: 0.615428\n",
      "Cost after epoch 30: 0.612295\n",
      "Cost after epoch 31: 0.610751\n",
      "Cost after epoch 32: 0.610924\n",
      "Cost after epoch 33: 0.607103\n",
      "Cost after epoch 34: 0.607084\n",
      "Cost after epoch 35: 0.606939\n",
      "Cost after epoch 36: 0.607465\n",
      "Cost after epoch 37: 0.607556\n",
      "Cost after epoch 38: 0.608212\n",
      "Cost after epoch 39: 0.604544\n",
      "Cost after epoch 40: 0.605286\n",
      "Cost after epoch 41: 0.605518\n",
      "Cost after epoch 42: 0.602378\n",
      "Cost after epoch 43: 0.604666\n",
      "Cost after epoch 44: 0.606132\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1de78eaaf28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[15000,32,32,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_X_0_0/_69, W1/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_1/_73 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_73_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'Conv2D', defined at:\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-102-4e65c4f9ab4d>\", line 1, in <module>\n    parameters = model(X_train,Y_train,X_d,Y_d,X_test,optimizer='adam',num_epochs=45,kp=0.8,learning_rate=0.0009)\n  File \"<ipython-input-101-3c5cd724aaf6>\", line 43, in model\n    Z3,keep_prob,cost = forward_propagation_cost(X,Y,parameters)\n  File \"<ipython-input-99-1c866b42caf6>\", line 23, in forward_propagation_cost\n    Z1 = conv2d(X,W1)+b1\n  File \"<ipython-input-17-6c92643fffa6>\", line 5, in conv2d\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 725, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[15000,32,32,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_X_0_0/_69, W1/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_1/_73 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_73_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[15000,32,32,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_X_0_0/_69, W1/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_1/_73 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_73_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-4e65c4f9ab4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_d\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_d\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m45\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0009\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-101-3c5cd724aaf6>\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(X_train, Y_train, X_test, Y_test, test, learning_rate, num_epochs, minibatch_size, print_cost, optimizer, kp)\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;31m# Calculate the correct predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;31m#train_accuracy = accuracy.eval({X: X_train, Y: Y_train,keep_prob:1.0})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mtest_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;31m#print(\"Train Accuracy:\", train_accuracy)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test Accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \"\"\"\n\u001b[1;32m--> 648\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   4756\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4757\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 4758\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4759\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1363\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[15000,32,32,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_X_0_0/_69, W1/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_1/_73 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_73_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'Conv2D', defined at:\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-102-4e65c4f9ab4d>\", line 1, in <module>\n    parameters = model(X_train,Y_train,X_d,Y_d,X_test,optimizer='adam',num_epochs=45,kp=0.8,learning_rate=0.0009)\n  File \"<ipython-input-101-3c5cd724aaf6>\", line 43, in model\n    Z3,keep_prob,cost = forward_propagation_cost(X,Y,parameters)\n  File \"<ipython-input-99-1c866b42caf6>\", line 23, in forward_propagation_cost\n    Z1 = conv2d(X,W1)+b1\n  File \"<ipython-input-17-6c92643fffa6>\", line 5, in conv2d\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 725, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Administrator\\Anaconda2\\envs\\ipykernel_py3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[15000,32,32,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_X_0_0/_69, W1/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_1/_73 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_73_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "parameters = model(X_train,Y_train,X_d,Y_d,X_test,optimizer='adam',num_epochs=45,kp=0.8,learning_rate=0.0009)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My laptop tended to run OOM everytime when my batch size is big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T04:32:26.996916Z",
     "start_time": "2018-02-27T04:32:26.991901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "loaded_y = np.load('ans-zz1749.npy')\n",
    "print(loaded_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T04:32:27.438163Z",
     "start_time": "2018-02-27T04:32:27.433149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list(loaded_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T04:32:29.667541Z",
     "start_time": "2018-02-27T04:32:29.664559Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict = {'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T04:32:29.980021Z",
     "start_time": "2018-02-27T04:32:29.977017Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T04:32:31.145802Z",
     "start_time": "2018-02-27T04:32:31.130716Z"
    }
   },
   "outputs": [],
   "source": [
    "dict = {'id':range(5000),'label':[list(dict.keys())[list(dict.values()).index(x)] for x in loaded_y]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T04:32:32.184542Z",
     "start_time": "2018-02-27T04:32:32.179513Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T04:32:36.828506Z",
     "start_time": "2018-02-27T04:32:36.806362Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('ans2-zz1749.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T04:59:29.656758Z",
     "start_time": "2018-02-26T04:59:29.647233Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_predictions('ans-zz1749.npy',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T22:06:23.799363Z",
     "start_time": "2018-02-26T22:06:23.793388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 2)\n"
     ]
    }
   ],
   "source": [
    "loaded_y = np.load('ans-zz1749.npy')\n",
    "print(loaded_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T22:06:28.709713Z",
     "start_time": "2018-02-26T22:06:28.704196Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['horse', 0],\n",
       "       ['frog', 1],\n",
       "       ['automobile', 2],\n",
       "       ...,\n",
       "       ['truck', 4997],\n",
       "       ['dog', 4998],\n",
       "       ['dog', 4999]], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T05:02:04.564420Z",
     "start_time": "2018-02-26T05:02:04.542362Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('ans-zz1749.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
