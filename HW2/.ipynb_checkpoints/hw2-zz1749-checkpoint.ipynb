{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:51:21.335139Z",
     "start_time": "2018-02-27T01:51:17.389855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "import imageio\n",
    "import scipy.misc\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:51:21.555387Z",
     "start_time": "2018-02-27T01:51:21.548368Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_files_train(folder):\n",
    "    \"\"\"\n",
    "    Given path to folder, returns list of files in it\n",
    "    \"\"\"\n",
    "    filenames = [file for file in glob.glob(folder+'*/*')]\n",
    "    filenames.sort(key= lambda x:int(x[11:x.index('_')]))\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:51:22.072688Z",
     "start_time": "2018-02-27T01:51:22.066672Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_files_test(folder):\n",
    "    \"\"\"\n",
    "    Given path to folder, returns list of files in it\n",
    "    \"\"\"\n",
    "    filenames = [file for file in glob.glob(folder+'*/*')]\n",
    "    filenames.sort(key= lambda x:int(x[10:x.index('.')]))\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:54:58.673451Z",
     "start_time": "2018-02-27T01:54:58.472497Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helper functions, DO NOT modify this\n",
    "\n",
    "def get_img_array(path):\n",
    "    \"\"\"\n",
    "    Given path of image, returns it's numpy array\n",
    "    \"\"\"\n",
    "    return imageio.imread(path)\n",
    "\n",
    "def resize_img(img_arr, target_dim=(50, 50)):\n",
    "    \"\"\"\n",
    "    Resizes img represented as numpy array\n",
    "    \"\"\"\n",
    "    return scipy.misc.imresize(img_arr, target_dim)\n",
    "\n",
    "def get_label(filepath, label2id):\n",
    "    \"\"\"\n",
    "    Files are assumed to be labeled as: /path/to/file/999_frog.png\n",
    "    Returns label for a filepath\n",
    "    \"\"\"\n",
    "    tokens = filepath.split('/')\n",
    "    label = tokens[-1].split('_')[1][:-4]\n",
    "    if label in label2id:\n",
    "        return label2id[label]\n",
    "    else:\n",
    "        sys.exit(\"Invalid label: \" + label)\n",
    "\n",
    "# Functions to load data\n",
    "\n",
    "def get_labels(folder, label2id):\n",
    "    \"\"\"\n",
    "    Returns vector of labels extracted from filenames of all files in folder\n",
    "    :param folder: path to data folder\n",
    "    :param label2id: mapping of text labels to numeric ids. (Eg: automobile -> 0)\n",
    "    \"\"\"\n",
    "    files = get_files_train(folder)\n",
    "    y = []\n",
    "    for f in files:\n",
    "        y.append(get_label(f,label2id))\n",
    "    return np.array(y)\n",
    "\n",
    "def one_hot(y, num_classes=10):\n",
    "    \"\"\"\n",
    "    Converts each label index in y to vector with one_hot encoding\n",
    "    \"\"\"\n",
    "    y_one_hot = np.zeros((y.shape[0], num_classes))\n",
    "    y_one_hot[y] = 1\n",
    "    return y_one_hot.T\n",
    "\n",
    "def get_label_mapping(label_file):\n",
    "    \"\"\"\n",
    "    Returns mappings of label to index and index to label\n",
    "    The input file has list of labels, each on a separate line.\n",
    "    \"\"\"\n",
    "    with open(label_file, 'r') as f:\n",
    "        id2label = f.readlines()\n",
    "        id2label = [l.strip() for l in id2label]\n",
    "    label2id = {}\n",
    "    count = 0\n",
    "    for label in id2label:\n",
    "        label2id[label] = count\n",
    "        count += 1\n",
    "    return id2label, label2id\n",
    "\n",
    "def get_images(folder):\n",
    "    \"\"\"\n",
    "    returns numpy array of all samples in folder\n",
    "    each column is a sample resized to 30x30 and flattened\n",
    "    \"\"\"\n",
    "    if 'train' in folder:\n",
    "        files = get_files_train(folder)\n",
    "    elif 'test' in folder:\n",
    "        files = get_files_test(folder)\n",
    "    images = []\n",
    "    count = 0\n",
    "\n",
    "    for f in files:\n",
    "        count += 1\n",
    "        if count % 5000 == 0:\n",
    "            print(\"Loaded {}/{}\".format(count,len(files)))\n",
    "#         if count > 100:\n",
    "#             break\n",
    "        img_arr = get_img_array(f)/255.0\n",
    "        images.append(img_arr)\n",
    "#     X = tf.map_fn(lambda image: tf.image.per_image_standardization(image), images, tf.int32)\n",
    "    X = np.array(images)\n",
    "#     X = images\n",
    "    return X\n",
    "\n",
    "def get_train_data(data_root_path, suffix=\"train\"):\n",
    "    \"\"\"\n",
    "    Return X and y\n",
    "    \"\"\"\n",
    "    train_data_path = data_root_path + suffix\n",
    "    id2label, label2id = get_label_mapping(data_root_path+'labels.txt')\n",
    "    print(label2id)\n",
    "    X = get_images(train_data_path)\n",
    "    y = get_labels(train_data_path, label2id)\n",
    "    return X, y\n",
    "\n",
    "def save_predictions(filename, y):\n",
    "    np.save(filename, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:55:40.696400Z",
     "start_time": "2018-02-27T01:54:59.524632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n",
      "Loaded 5000/45000\n",
      "Loaded 10000/45000\n",
      "Loaded 15000/45000\n",
      "Loaded 20000/45000\n",
      "Loaded 25000/45000\n",
      "Loaded 30000/45000\n",
      "Loaded 35000/45000\n",
      "Loaded 40000/45000\n",
      "Loaded 45000/45000\n",
      "Train data loading done\n"
     ]
    }
   ],
   "source": [
    "# Load train data\n",
    "data_root_path = 'data/'\n",
    "# data_root_path = './cifar10-simple/'\n",
    "X_train, y_train = get_train_data(data_root_path) # this may take a few minutes\n",
    "# X_centered = (X_train - np.mean(X_train, axis=1)[:, np.newaxis])\n",
    "# X_div = (X_centered / np.std(X_centered, axis=1)[:, np.newaxis])\n",
    "# X_train = X_div\n",
    "print('Train data loading done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:55:47.517563Z",
     "start_time": "2018-02-27T01:55:47.487457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 32, 32, 3) (45000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:56:56.386450Z",
     "start_time": "2018-02-27T01:56:51.174111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5000/5000\n",
      "Test data loading done\n"
     ]
    }
   ],
   "source": [
    "#Load test data\n",
    "X_test = get_images(data_root_path + 'test')\n",
    "# X_centered = (X_test - np.mean(X_test, axis=1)[:, np.newaxis])\n",
    "# X_div = (X_centered / np.std(X_centered, axis=1)[:, np.newaxis])\n",
    "# X_test = X_div\n",
    "print('Test data loading done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:57:02.915489Z",
     "start_time": "2018-02-27T01:57:02.910475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 32, 32, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:57:06.604252Z",
     "start_time": "2018-02-27T01:57:06.554538Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot_matrix(labels, C):\n",
    "    \"\"\"\n",
    "    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n",
    "                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) \n",
    "                     will be 1. \n",
    "                     \n",
    "    Arguments:\n",
    "    labels -- vector containing the labels \n",
    "    C -- number of classes, the depth of the one hot dimension\n",
    "    \n",
    "    Returns: \n",
    "    one_hot -- one hot matrix\n",
    "    \"\"\"\n",
    "    # Create a tf.constant equal to C (depth), name it 'C'. (approx. 1 line)\n",
    "    C = tf.constant(C, name='C')\n",
    "    \n",
    "    # Use tf.one_hot, be careful with the axis (approx. 1 line)\n",
    "    one_hot_matrix = tf.one_hot(labels,C,1)\n",
    "    \n",
    "    # Create the session (approx. 1 line)\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # Run the session (approx. 1 line)\n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "    \n",
    "    # Close the session (approx. 1 line). See method 1 above.\n",
    "    sess.close()\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:57:10.656825Z",
     "start_time": "2018-02-27T01:57:07.722003Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_train = one_hot_matrix(y_train,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:57:14.336584Z",
     "start_time": "2018-02-27T01:57:14.327110Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_H0 -- scalar, height of an input image\n",
    "    n_W0 -- scalar, width of an input image\n",
    "    n_C0 -- scalar, number of channels of the input\n",
    "    n_y -- scalar, number of classes\n",
    "        \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [None, n_y] and dtype \"float\"\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (≈2 lines)\n",
    "    X = tf.placeholder(tf.float32,shape=[None,n_H0,n_W0,n_C0],name='X')\n",
    "    Y = tf.placeholder(tf.float32,shape=[None,n_y],name='Y')\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:57:15.386521Z",
     "start_time": "2018-02-27T01:57:15.371512Z"
    }
   },
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes weight parameters to build a neural network with tensorflow. \n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, W2\n",
    "    \"\"\"\n",
    "    \n",
    "        \n",
    "    ### START CODE HERE ### (approx. 2 lines of code)\n",
    "    W1 = tf.get_variable('W1',[5,5,3,64],initializer= tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    b1 = tf.get_variable('b1',[64],initializer= tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W2 = tf.get_variable('W2',[5,5,64,64],initializer= tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    b2 = tf.get_variable('b2',[64],initializer= tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2,\n",
    "                 'b1':b1,\n",
    "                 'b2':b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:57:16.391967Z",
     "start_time": "2018-02-27T01:57:16.383945Z"
    }
   },
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    return tf.nn.lrn(x, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "def max_pool_2x2(x): return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T04:17:18.433108Z",
     "start_time": "2018-02-27T04:17:18.390485Z"
    }
   },
   "outputs": [],
   "source": [
    "def forward_propagation_cost(X,Y,parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"W2\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    b1 = parameters['b1']\n",
    "    b2 = parameters['b2']\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # CONV2D: stride of 1, padding 'SAME'\n",
    "    Z1 = conv2d(X,W1)+b1\n",
    "    # RELU\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    # MAXPOOL: window 8x8, sride 8, padding 'SAME'\n",
    "    P1 = norm(max_pool_2x2(A1))\n",
    "    # CONV2D: filters W2, stride 1, padding 'SAME'\n",
    "    Z2 = conv2d(P1,W2)+b2\n",
    "    # RELU\n",
    "    A2 = norm(tf.nn.relu(Z2))\n",
    "    # MAXPOOL: window 4x4, stride 4, padding 'SAME'\n",
    "    P2 = max_pool_2x2(A2)\n",
    "    # FLATTEN\n",
    "    P2 = tf.contrib.layers.flatten(P2)\n",
    "    \n",
    "    # 10 neurons in output layer. Hint: one of the arguments should be \"activation_fn=None\" \n",
    "    \n",
    "    keep_prob = tf.placeholder(tf.float32,name='keep_prob')\n",
    "    P2 = tf.nn.dropout(P2,keep_prob)\n",
    "    Z3 = tf.contrib.layers.fully_connected(P2,10,activation_fn=None)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z3,labels=Y))\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return Z3, keep_prob, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T04:17:18.637698Z",
     "start_time": "2018-02-27T04:17:18.591570Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n",
    "    mini_batch_size -- size of the mini-batches, integer\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(seed)            # To make your \"random\" minibatches the same as ours\n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "        \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:,:]\n",
    "    shuffled_Y = Y[permutation,:]\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = shuffled_X[k*mini_batch_size:(k+1)*mini_batch_size,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[k*mini_batch_size:(k+1)*mini_batch_size,:]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches*mini_batch_size:,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches*mini_batch_size:,:]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T04:32:29.667541Z",
     "start_time": "2018-02-27T04:32:29.664559Z"
    }
   },
   "outputs": [],
   "source": [
    "dict = {'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T04:17:19.075419Z",
     "start_time": "2018-02-27T04:17:18.844212Z"
    }
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test,test, learning_rate = 0.1,\n",
    "          num_epochs = 100, minibatch_size = 64, print_cost = True, optimizer='GD',kp=1.0):\n",
    "    \"\"\"\n",
    "    Implements a three-layer ConvNet in Tensorflow:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set\n",
    "    Y_train -- test set\n",
    "    X_test -- training set\n",
    "    Y_test -- test set\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    train_accuracy -- real number, accuracy on the train set (X_train)\n",
    "    test_accuracy -- real number, testing accuracy on the test set (X_test)\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    print(test.shape)\n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep results consistent (tensorflow seed)\n",
    "    seed = 3                                          # to keep results consistent (numpy seed)\n",
    "    (m, n_H0, n_W0, n_C0) = X_train.shape             \n",
    "    n_y = Y_train.shape[1]                            \n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of the correct shape\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = create_placeholders(n_H0,n_W0,n_C0,n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z3,keep_prob,cost = forward_propagation_cost(X,Y,parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    #global_ = tf.Variable(tf.constant(0))  \n",
    "    global_step = tf.Variable(0)\n",
    "    lr = tf.train.exponential_decay(learning_rate,global_step,705,0.88,staircase=False)\n",
    "    if optimizer == 'GD':\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr).minimize(cost,global_step=global_step)\n",
    "    elif optimizer == 'adam':\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost,global_step=global_step)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables globally\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            minibatch_cost = 0.\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "            \n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                # IMPORTANT: The line that runs the graph on a mfinibatch.\n",
    "                # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , temp_cost = sess.run([optimizer,cost],feed_dict={keep_prob:kp,X:minibatch_X,Y:minibatch_Y})\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "            \n",
    "            predict_op = tf.argmax(Z3, 1)\n",
    "            Y_train_pred = predict_op.eval({X: minibatch_X,keep_prob:1.0})\n",
    "            Y_train_orig = [np.argwhere(x==1)[0][0] for x in minibatch_Y]\n",
    "            Y_test_pred = predict_op.eval({X: X_test,keep_prob:1.0})\n",
    "            Y_test_orig = [np.argwhere(x==1)[0][0] for x in Y_test]\n",
    "            train_acc = 100.0*sum(Y_train_pred==Y_train_orig)/len(Y_train_orig)\n",
    "            test_acc = 100.0*sum(Y_test_pred==Y_test_orig)/len(Y_test_orig)\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                print (\"Cost after epoch %i: %f, train accuracy: %f, test accuracy: %f\" % (epoch, minibatch_cost, train_acc, test_acc))\n",
    "\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(minibatch_cost)\n",
    "        \n",
    "        \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "        #predict_op = tf.argmax(Z3, 1)\n",
    "        #correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        #accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        save_predictions('ans-zz1749.npy',predict_op.eval({X: test,keep_prob:1.0}))\n",
    "        # Calculate the correct predictions\n",
    "        # train_accuracy = accuracy.eval({X: X_train, Y: Y_train,keep_prob:0.8})\n",
    "        # test_accuracy = accuracy.eval({X: X_test, Y: Y_test,keep_prob:0.8})\n",
    "        #print(\"Train Accuracy:\", train_accuracy)\n",
    "        #print(\"Test Accuracy:\", test_accuracy)\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T03:12:40.915886Z",
     "start_time": "2018-02-27T03:12:40.305117Z"
    }
   },
   "outputs": [],
   "source": [
    "X_t,X_d,Y_t,Y_d = train_test_split(X_train,Y_train,test_size = 1./3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T04:30:40.943795Z",
     "start_time": "2018-02-27T04:17:27.051219Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 32, 32, 3)\n",
      "Cost after epoch 0: 1.584687, train accuracy: 75.000000, test accuracy: 52.606667\n",
      "Cost after epoch 1: 1.247388, train accuracy: 37.500000, test accuracy: 60.280000\n",
      "Cost after epoch 2: 1.100087, train accuracy: 75.000000, test accuracy: 65.220000\n",
      "Cost after epoch 3: 1.004681, train accuracy: 100.000000, test accuracy: 68.693333\n",
      "Cost after epoch 4: 0.937924, train accuracy: 50.000000, test accuracy: 70.360000\n",
      "Cost after epoch 5: 0.883074, train accuracy: 75.000000, test accuracy: 72.646667\n",
      "Cost after epoch 6: 0.837138, train accuracy: 87.500000, test accuracy: 74.500000\n",
      "Cost after epoch 7: 0.805721, train accuracy: 62.500000, test accuracy: 74.686667\n",
      "Cost after epoch 8: 0.776463, train accuracy: 100.000000, test accuracy: 75.173333\n",
      "Cost after epoch 9: 0.756324, train accuracy: 100.000000, test accuracy: 76.553333\n",
      "Cost after epoch 10: 0.736400, train accuracy: 75.000000, test accuracy: 77.406667\n",
      "Cost after epoch 11: 0.716784, train accuracy: 62.500000, test accuracy: 77.506667\n",
      "Cost after epoch 12: 0.701848, train accuracy: 62.500000, test accuracy: 77.900000\n",
      "Cost after epoch 13: 0.689967, train accuracy: 87.500000, test accuracy: 78.813333\n",
      "Cost after epoch 14: 0.676890, train accuracy: 50.000000, test accuracy: 78.686667\n",
      "Cost after epoch 15: 0.672102, train accuracy: 75.000000, test accuracy: 79.213333\n",
      "Cost after epoch 16: 0.663241, train accuracy: 75.000000, test accuracy: 79.673333\n",
      "Cost after epoch 17: 0.652150, train accuracy: 87.500000, test accuracy: 79.933333\n",
      "Cost after epoch 18: 0.646781, train accuracy: 87.500000, test accuracy: 80.193333\n",
      "Cost after epoch 19: 0.641899, train accuracy: 87.500000, test accuracy: 80.453333\n",
      "Cost after epoch 20: 0.637514, train accuracy: 75.000000, test accuracy: 80.326667\n",
      "Cost after epoch 21: 0.632580, train accuracy: 100.000000, test accuracy: 80.720000\n",
      "Cost after epoch 22: 0.633266, train accuracy: 75.000000, test accuracy: 80.800000\n",
      "Cost after epoch 23: 0.625228, train accuracy: 87.500000, test accuracy: 80.780000\n",
      "Cost after epoch 24: 0.619668, train accuracy: 75.000000, test accuracy: 80.886667\n",
      "Cost after epoch 25: 0.621361, train accuracy: 75.000000, test accuracy: 80.953333\n",
      "Cost after epoch 26: 0.615717, train accuracy: 75.000000, test accuracy: 81.120000\n",
      "Cost after epoch 27: 0.616733, train accuracy: 87.500000, test accuracy: 81.346667\n",
      "Cost after epoch 28: 0.613953, train accuracy: 75.000000, test accuracy: 81.260000\n",
      "Cost after epoch 29: 0.612544, train accuracy: 100.000000, test accuracy: 81.306667\n",
      "Cost after epoch 30: 0.612465, train accuracy: 50.000000, test accuracy: 81.346667\n",
      "Cost after epoch 31: 0.613824, train accuracy: 75.000000, test accuracy: 81.513333\n",
      "Cost after epoch 32: 0.608957, train accuracy: 87.500000, test accuracy: 81.513333\n",
      "Cost after epoch 33: 0.608459, train accuracy: 75.000000, test accuracy: 81.520000\n",
      "Cost after epoch 34: 0.607303, train accuracy: 62.500000, test accuracy: 81.533333\n",
      "Cost after epoch 35: 0.603587, train accuracy: 87.500000, test accuracy: 81.673333\n",
      "Cost after epoch 36: 0.605595, train accuracy: 87.500000, test accuracy: 81.693333\n",
      "Cost after epoch 37: 0.605902, train accuracy: 62.500000, test accuracy: 81.733333\n",
      "Cost after epoch 38: 0.604072, train accuracy: 75.000000, test accuracy: 81.673333\n",
      "Cost after epoch 39: 0.601142, train accuracy: 87.500000, test accuracy: 81.680000\n",
      "Cost after epoch 40: 0.605834, train accuracy: 87.500000, test accuracy: 81.726667\n",
      "Cost after epoch 41: 0.603913, train accuracy: 75.000000, test accuracy: 81.773333\n",
      "Cost after epoch 42: 0.603420, train accuracy: 100.000000, test accuracy: 81.753333\n",
      "Cost after epoch 43: 0.602143, train accuracy: 62.500000, test accuracy: 81.780000\n",
      "Cost after epoch 44: 0.603093, train accuracy: 75.000000, test accuracy: 81.813333\n",
      "Cost after epoch 45: 0.602738, train accuracy: 87.500000, test accuracy: 81.760000\n",
      "Cost after epoch 46: 0.603454, train accuracy: 75.000000, test accuracy: 81.726667\n",
      "Cost after epoch 47: 0.603745, train accuracy: 75.000000, test accuracy: 81.773333\n",
      "Cost after epoch 48: 0.599936, train accuracy: 75.000000, test accuracy: 81.780000\n",
      "Cost after epoch 49: 0.599424, train accuracy: 87.500000, test accuracy: 81.806667\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = model(X_train,Y_train,X_d,Y_d,X_test,optimizer='adam',num_epochs=50,kp=0.8,learning_rate=0.0009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T04:32:26.996916Z",
     "start_time": "2018-02-27T04:32:26.991901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "loaded_y = np.load('ans-zz1749.npy')\n",
    "print(loaded_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T04:32:27.438163Z",
     "start_time": "2018-02-27T04:32:27.433149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list(loaded_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T04:32:31.145802Z",
     "start_time": "2018-02-27T04:32:31.130716Z"
    }
   },
   "outputs": [],
   "source": [
    "dict = {'id':range(5000),'label':[list(dict.keys())[list(dict.values()).index(x)] for x in loaded_y]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T04:32:32.184542Z",
     "start_time": "2018-02-27T04:32:32.179513Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T04:32:36.828506Z",
     "start_time": "2018-02-27T04:32:36.806362Z"
    }
   },
   "outputs": [],
   "source": [
    "data.to_csv('ans2-zz1749.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T04:59:29.656758Z",
     "start_time": "2018-02-26T04:59:29.647233Z"
    }
   },
   "outputs": [],
   "source": [
    "save_predictions('ans-zz1749.npy',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T22:06:23.799363Z",
     "start_time": "2018-02-26T22:06:23.793388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 2)\n"
     ]
    }
   ],
   "source": [
    "loaded_y = np.load('ans-zz1749.npy')\n",
    "print(loaded_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T22:06:28.709713Z",
     "start_time": "2018-02-26T22:06:28.704196Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 'horse'],\n",
       "       [1, 'automobile'],\n",
       "       [2, 'deer'],\n",
       "       ...,\n",
       "       [4997, 'airplane'],\n",
       "       [4998, 'automobile'],\n",
       "       [4999, 'automobile']], dtype=object)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T05:02:04.564420Z",
     "start_time": "2018-02-26T05:02:04.542362Z"
    }
   },
   "outputs": [],
   "source": [
    "data.to_csv('ans-zz1749.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
